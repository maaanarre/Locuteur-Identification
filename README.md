# Locuteur-Identification

# ğŸ”Š Projet : Identification et VÃ©rification du Locuteur

Ce projet implÃ©mente un systÃ¨me d'identification et de vÃ©rification du locuteur basÃ© sur des enregistrements audio, utilisant des **ModÃ¨les de MÃ©lange Gaussien (GMM)** et des **coefficients MFCC**. Deux mÃ©thodes de prÃ©traitement vocal sont comparÃ©es : **WebRTC VAD** et **Librosa Split**. 
---

## ğŸ¯ Objectifs

- Mettre en Å“uvre un systÃ¨me d'identification et de vÃ©rification basÃ© sur la voix.
- Comparer deux techniques de suppression du silence (WebRTC VAD vs. Librosa).
- Ã‰valuer l'impact du **nombre de gaussiennes** et de la **durÃ©e des segments audio**.
- Visualiser les performances via des **courbes DET** et mesurer le **Equal Error Rate (EER)**.

---

## ğŸ“¦ Dataset

- **23 locuteurs** : 13 femmes (F1â€“F13), 10 hommes (H1â€“H10)
- **EntraÃ®nement** : 1 fichier de 2 minutes par locuteur
- **Test** : 15 fichiers par locuteur (5 Ã— 5s, 5 Ã— 10s, 5 Ã— 15s)

---

## ğŸ§° Outils et bibliothÃ¨ques utilisÃ©s

- `Python 3.x`
- `librosa` â€“ traitement du signal audio
- `numpy`, `pandas` â€“ traitement de donnÃ©es
- `soundfile` â€“ sauvegarde audio
- `matplotlib` â€“ visualisation
- `scikit-learn` â€“ GMM et Ã©valuation
- `webrtcvad` â€“ dÃ©tection dâ€™activitÃ© vocale (VAD)
- `joblib` â€“ sauvegarde des modÃ¨les

---

## ğŸ” Pipeline de traitement

```text
1. Chargement des fichiers audio (16 kHz)
2. Suppression des silences :
   a. WebRTC VAD (trames 30 ms, PCM 16 bits)
   b. Librosa Split (top_db = 30)
3. Extraction MFCCs
4. EntraÃ®nement GMM (8 Ã  256 gaussiennes)
5. Identification & VÃ©rification
6. Ã‰valuation (courbes DET, EER)
