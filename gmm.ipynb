{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0642ad6-287b-4f76-8a50-f968aaaf3b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm \n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7068c67b-a142-411c-8115-7ecc4babcb76",
   "metadata": {},
   "source": [
    "link to the dataset \n",
    "https://drive.google.com/file/d/1G-6A60OhBvURa0GC3ry9FpvKI1mk1t2W/view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2af649da-0313-4c4d-91f7-f1f2573a4602",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"Reconnaissance_du_locuteur\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39445c55-9d83-4c7c-8767-30cbd99158ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_silence(audio_path, output_path, top_db=30):\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "    non_silent_intervals = librosa.effects.split(y, top_db=top_db)\n",
    "    y_trimmed = np.concatenate([y[start:end] for start, end in non_silent_intervals])\n",
    "    sf.write(output_path, y_trimmed, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19a1e466-52af-4d4f-b71b-a4a3b54776c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Speakers: 100%|█████████████████████████████████████████████████████████████| 23/23 [01:04<00:00,  2.81s/it]\n"
     ]
    }
   ],
   "source": [
    "for speaker in tqdm(os.listdir(path), desc=\"Processing Speakers\"):\n",
    "    speaker_path = os.path.join(path, speaker)\n",
    "    for subfolder in [\"train\", \"test\"]:\n",
    "        subfolder_path = os.path.join(speaker_path, subfolder)\n",
    "        if subfolder == \"test\":\n",
    "                    # Process the 5s, 10s, 15s subfolders\n",
    "                    for duration in [\"5s\", \"10s\", \"15s\"]:\n",
    "                        duration_path = os.path.join(subfolder_path, duration)\n",
    "                        for file in os.listdir(duration_path):\n",
    "                                input_path = os.path.join(duration_path, file)\n",
    "                                output_path = os.path.join(duration_path, f\"cleaned_{file}\")\n",
    "                                remove_silence(input_path, output_path)\n",
    "        else:\n",
    "            for file in os.listdir(subfolder_path):\n",
    "                            input_path = os.path.join(subfolder_path, file)\n",
    "                            output_path = os.path.join(subfolder_path, f\"cleaned_{file}\")\n",
    "                            remove_silence(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a10e3521-8595-4ea3-9e74-5b061011c7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing speakers: 100%|█████████████████████████████████████████████████████████████| 23/23 [00:11<00:00,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC features saved to mfcc_features.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def extract_mfcc(audio_path, n_mfcc=13):\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    return np.mean(mfccs, axis=1)  # Taking mean across time axis\n",
    "\n",
    "def process_cleaned_train(root_path, output_csv):\n",
    "    data = []\n",
    "    \n",
    "    for speaker_folder in tqdm(os.listdir(root_path), desc=\"Processing speakers\"):\n",
    "        speaker_path = os.path.join(root_path, speaker_folder)\n",
    "        train_path = os.path.join(speaker_path, \"Train\")\n",
    "        \n",
    "        if os.path.exists(train_path):  # Ensure 'Train' folder exists\n",
    "            cleaned_audio_path = os.path.join(train_path, \"cleaned_Train.wav\")  # Adjust if extension varies\n",
    "            \n",
    "            if os.path.exists(cleaned_audio_path):  # Ensure the file exists\n",
    "                mfcc_features = extract_mfcc(cleaned_audio_path)\n",
    "                data.append([speaker_folder] + mfcc_features.tolist())\n",
    "\n",
    "    columns = [\"Speaker\"] + [f\"MFCC_{i+1}\" for i in range(len(mfcc_features))]\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"MFCC features saved to {output_csv}\")\n",
    "\n",
    "root_path = path\n",
    "output_csv = \"mfcc_features.csv\"\n",
    "process_cleaned_train(root_path, output_csv)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6fdd3f06-dda7-481f-b076-4ebdcfdbe000",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing speakers: 100%|█████████████████████████████████████████████████████████████| 23/23 [00:06<00:00,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC features saved to mfcc_features2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_and_process_mfcc(audio_path, n_mfcc=13):\n",
    "    \"\"\"Extract MFCCs, remove low-energy frames, and return the mean across time axis.\"\"\"\n",
    "    # Load audio\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "    \n",
    "    # Extract MFCCs\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    \n",
    "    # Remove the first coefficient (energy)\n",
    "    mfcc = mfcc[1:, :]\n",
    "    \n",
    "    # Return the mean of MFCCs across time axis\n",
    "    return np.mean(mfcc, axis=1)\n",
    "\n",
    "def process_cleaned_train(root_path, output_csv, n_mfcc=13):\n",
    "    data = []\n",
    "    \n",
    "    for speaker_folder in tqdm(os.listdir(root_path), desc=\"Processing speakers\"):\n",
    "        speaker_path = os.path.join(root_path, speaker_folder)\n",
    "        train_path = os.path.join(speaker_path, \"Train\")\n",
    "        \n",
    "        if os.path.exists(train_path):  # Ensure 'Train' folder exists\n",
    "            cleaned_audio_path = os.path.join(train_path, \"cleaned_Train.wav\")  # Adjust if extension varies\n",
    "            \n",
    "            if os.path.exists(cleaned_audio_path):  # Ensure the file exists\n",
    "                # Extract MFCC features and compute the mean\n",
    "                mfcc_features = extract_and_process_mfcc(cleaned_audio_path, n_mfcc)\n",
    "                data.append([speaker_folder] + mfcc_features.tolist())\n",
    "    \n",
    "    # Create DataFrame and save to CSV\n",
    "    columns = [\"Speaker\"] + [f\"MFCC_{i+1}\" for i in range(n_mfcc-1)]  # n_mfcc-1 because the first coefficient is dropped\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"MFCC features saved to {output_csv}\")\n",
    "\n",
    "# Path setup\n",
    "root_path = path  # Replace with the actual root path\n",
    "output_csv = \"mfcc_features2.csv\"\n",
    "process_cleaned_train(root_path, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3b91b324-8dc4-4288-94e2-6385c5cd1b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing speakers: 100%|█████████████████████████████████████████████████████████████| 23/23 [00:06<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC features saved to mfcc_features2.csv\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_mfcc(audio_path, n_mfcc=13):\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "    # Extract MFCC features frame-by-frame\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    return mfccs.T  # Transpose to have shape (n_frames, n_mfcc)\n",
    "\n",
    "def process_cleaned_train(root_path, output_csv, n_mfcc=13):\n",
    "    data = []\n",
    "    \n",
    "    for speaker_folder in tqdm(os.listdir(root_path), desc=\"Processing speakers\"):\n",
    "        speaker_path = os.path.join(root_path, speaker_folder)\n",
    "        train_path = os.path.join(speaker_path, \"Train\")\n",
    "        \n",
    "        if os.path.exists(train_path):  # Ensure 'Train' folder exists\n",
    "            cleaned_audio_path = os.path.join(train_path, \"cleaned_Train.wav\")  # Adjust if extension varies\n",
    "            \n",
    "            if os.path.exists(cleaned_audio_path):  # Ensure the file exists\n",
    "                # Extract MFCC features from all frames\n",
    "                mfcc_frames = extract_mfcc(cleaned_audio_path, n_mfcc)\n",
    "                \n",
    "                # Add each MFCC frame to the data list\n",
    "                for frame in mfcc_frames:\n",
    "                    data.append([speaker_folder] + frame.tolist())  # Append each frame for the speaker\n",
    "\n",
    "    # Generate columns for the DataFrame\n",
    "    columns = [\"Speaker\"] + [f\"MFCC_{i+1}\" for i in range(n_mfcc)]\n",
    "    \n",
    "    # Create DataFrame and save to CSV\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"MFCC features saved to {output_csv}\")\n",
    "\n",
    "# Path setup\n",
    "root_path = path  # Replace with the actual root path\n",
    "output_csv = \"mfcc_features2.csv\"\n",
    "process_cleaned_train(root_path, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbc236a8-8360-4b59-b25d-b8d8940eff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_csv = \"mfcc_features2.csv\"  # Remplace par le chemin de ton fichier CSV\n",
    "df = pd.read_csv(mfcc_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d548bf2-0e47-4b73-9124-882f872c2819",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_root = \"gmm\"\n",
    "os.makedirs(gmm_root, exist_ok=True)\n",
    "gaussiennes_list = [8, 16, 32, 64, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cc499bd9-2e30-4b04-abf4-37ccd39ba813",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                 | 0/23 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 1 sample(s) (shape=(1, 13)) while a minimum of 2 is required by GaussianMixture.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gaussiennes \u001b[38;5;129;01min\u001b[39;00m gaussiennes_list:\n\u001b[0;32m     12\u001b[0m     gmm \u001b[38;5;241m=\u001b[39m GaussianMixture(n_components\u001b[38;5;241m=\u001b[39mgaussiennes, covariance_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiag\u001b[39m\u001b[38;5;124m'\u001b[39m, n_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m     gmm\u001b[38;5;241m.\u001b[39mfit(speaker_data)  \u001b[38;5;66;03m# Entraîner le modèle GMM\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Sauvegarde du modèle\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     model_filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(speaker_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGMM_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_components\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\mixture\\_base.py:181\u001b[0m, in \u001b[0;36mBaseMixture.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Estimate model parameters with the EM algorithm.\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mThe method fits the model ``n_init`` times and sets the parameters with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m    The fitted mixture.\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# parameters are validated in fit_predict\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_predict(X, y)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\mixture\\_base.py:212\u001b[0m, in \u001b[0;36mBaseMixture.fit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    186\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Estimate model parameters using X and predict the labels for X.\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \n\u001b[0;32m    188\u001b[0m \u001b[38;5;124;03m    The method fits the model n_init times and sets the parameters with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m        Component labels.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, dtype\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32], ensure_min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components:\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    215\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected n_samples >= n_components \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    216\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got n_components = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    218\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1072\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1070\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m   1071\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m-> 1072\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1073\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1074\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1075\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m   1076\u001b[0m         )\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1079\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 1 sample(s) (shape=(1, 13)) while a minimum of 2 is required by GaussianMixture."
     ]
    }
   ],
   "source": [
    "for speaker in tqdm(df[\"Speaker\"].unique(), desc=\"Training\"):\n",
    "    speaker_data = df[df[\"Speaker\"] == speaker].iloc[:, 1:].values  # Exclure la colonne 'Speaker'\n",
    "    \n",
    "    if speaker_data.shape[0] == 0:\n",
    "        print(f\"Aucun MFCC trouvé pour {speaker}, skipping...\")\n",
    "        continue\n",
    "\n",
    "    speaker_folder = os.path.join(gmm_root, speaker)\n",
    "    os.makedirs(speaker_folder, exist_ok=True)\n",
    "\n",
    "    for gaussiennes in gaussiennes_list:\n",
    "        gmm = GaussianMixture(n_components=gaussiennes, covariance_type='diag', n_init=3, random_state=42)\n",
    "        gmm.fit(speaker_data)  # Entraîner le modèle GMM\n",
    "\n",
    "        # Sauvegarde du modèle\n",
    "        model_filename = os.path.join(speaker_folder, f\"GMM_{n_components}.pkl\")\n",
    "        with open(model_filename, \"wb\") as model_file:\n",
    "            pickle.dump(gmm, model_file)\n",
    "\n",
    "print(f\"Tous les modèles GMM sont sauvegardés dans {gmm_root}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb5236b5-8581-45c8-91ee-ea3a5583fbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker\n",
      "F1     1\n",
      "F9     1\n",
      "H7     1\n",
      "H6     1\n",
      "H5     1\n",
      "H4     1\n",
      "H3     1\n",
      "H2     1\n",
      "H11    1\n",
      "H10    1\n",
      "H1     1\n",
      "F8     1\n",
      "F10    1\n",
      "F7     1\n",
      "F6     1\n",
      "F5     1\n",
      "F4     1\n",
      "F3     1\n",
      "F2     1\n",
      "F13    1\n",
      "F12    1\n",
      "F11    1\n",
      "H9     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger les MFCCs\n",
    "mfcc_csv = \"mfcc_features.csv\"  # Mets le bon chemin\n",
    "df = pd.read_csv(mfcc_csv)\n",
    "\n",
    "# Vérifier le nombre d'échantillons par locuteur\n",
    "speaker_counts = df[\"Speaker\"].value_counts()\n",
    "\n",
    "# Afficher les locuteurs qui ont moins de 2 échantillons\n",
    "print(speaker_counts[speaker_counts < 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dacd6eb-5bc0-457c-b6ad-bbe54b0a7ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
